{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Authorship in the Federalist Papers</H1>\n",
    "Use this notebook to replicate the results reporter in the paper  </br>\n",
    "<ul>\n",
    "    [1] <a href = https://arxiv.org/abs/1911.01208>\n",
    "    Kipnis, A., ``Higher Criticism for Discriminating Word-Frequency Tables and Testing Authorship'', 2019\n",
    "    </a>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an HC-based test to provide out-of-the-box solution to the case studied in\n",
    "<ul>\n",
    "    [2] Mosteller, Frederick, and David L. Wallace. ``<em>Inference in an authorship problem: A comparative study of discrimination methods applied to the authorship of the disputed Federalist Papers</em>''. Journal of the American Statistical Association 58, no. 302 (1963): 275-309.\n",
    " </ul>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import auxiliary functions for python\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from AuthAttLib.AuthAttLib import *\n",
    "from AuthAttLib.FreqTable import *\n",
    "from AuthAttLib.text_processing import *\n",
    "from AuthAttLib.visualize_HC_scores import *\n",
    "from AuthAttLib.utils import *\n",
    "import plotnine\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions for parsing, processing, and cleaning text. \n",
    "\"\"\"\n",
    "import re\n",
    "import bs4 \n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "def remove_parts_of_speach(text, \n",
    "                        to_remove=('NNP', 'NNPS', 'CD'),\n",
    "                        lemmatize=True,\n",
    "                        remove_punct=False\n",
    "                        ) :\n",
    "    # 'NNP'-- proper noun, singluar\n",
    "    # 'NNPS' -- proper noun, plural \n",
    "    # 'CD' -- cardinal digit\n",
    "    # 'PRP' -- personal pronoun\n",
    "    # 'PRP$' -- posessive pronoun\n",
    "    # stem and remove numbers\n",
    "    text_pos = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    \n",
    "    #from text_processing import remove_parts_of_speach\n",
    "    punct = [':',';','\"','(',')','-',',','.','`','\\`','!','?']\n",
    "\n",
    "    if lemmatize :\n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        lemmas = [lemmatizer.lemmatize(w[0]) for w in text_pos if \\\n",
    "                  not w[1] in to_remove and \n",
    "                  (len(re.findall('[0-9]',w[0])) == 0) and \n",
    "                  w[0] not in punct]\n",
    "    else :\n",
    "        lemmas = [w[0] for w in text_pos if \\\n",
    "                  w[1] not in to_remove and\n",
    "                (len(re.findall('[0-9]',w[0])) == 0) and\n",
    "                  w[0] not in punct]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def html_to_text(text_in_html) :\n",
    "    soup = bs4.BeautifulSoup(text_in_html, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def stem_text(text, lang = 'english') :\n",
    "    stemmer = SnowballStemmer(lang)\n",
    "    return \" \".join([stemmer.stem(w) for w in re.split('\\W+', text)])\n",
    "\n",
    "def collapse_terms(lo_terms, term, text) :\n",
    "    #replaces every word in 'text' appearing in 'lo_terms' with 'term'\n",
    "    for st in lo_terms :\n",
    "        text = \" \".join([w.replace(st,term) for w in text.split()])\n",
    "    return text\n",
    "\n",
    "def remove_digits(text) :\n",
    "    return re.sub(\"[0-9]\", \"\", text)\n",
    "\n",
    "def remove_hexa_symbols(text) :\n",
    "    #replace with a space\n",
    "    return re.sub(\"\\\\\\\\x[0-9a-f]+\",\" \",text)\n",
    "\n",
    "def preprocess_text(text, stem = True, clean_names = True,\n",
    "               clean_html_tags = True, clean_digits = True\n",
    "               ) : \n",
    "    \n",
    "    text_st = text\n",
    "    \n",
    "    if clean_html_tags : \n",
    "        text_st = html_to_text(text_st)\n",
    "    \n",
    "    if stem :\n",
    "        text_st = stem_text(text_st)\n",
    "        \n",
    "    if clean_names :\n",
    "        text_st = remove_proper_names(text_st)\n",
    "        #lo_proper_names = find_capitalized_words(text_st)\n",
    "        #text_st = \" \".join(w for w in text_st.split() if w not in lo_proper_names)\n",
    "        \n",
    "    if clean_digits :\n",
    "        text_st = remove_digits(text_st)\n",
    "    \n",
    "    return text_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Load Data</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading first 77 Federalists Papers:\n",
      "Documents loaded:\n",
      "\t 43 Hamilton papers\n",
      "\t 14 Madison papers\n",
      "\t 12 disputed papers\n"
     ]
    }
   ],
   "source": [
    "print(\"loading first 77 Federalists Papers:\")\n",
    "from LoadFederalistPapers import load_Federalists_Papers\n",
    "fed_papers = load_Federalists_Papers(path = \"./Federalist_Papers.txt\")\n",
    "\n",
    "# arrange data in the format accepted by AuthAttribLib.AuthorshipAttributionMulti:\n",
    "# pandas DataFrame with columns 'doc_id', 'author', 'text'\n",
    "fed_papers.loc[:,'doc_id'] = fed_papers.paper_no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 1995\n"
     ]
    }
   ],
   "source": [
    "#1500 most frequent words by each author, unionized\n",
    "punct = ['!','?',':',';','\"','(',')','-',',','.','`','\\`','``','\\'\\'']\n",
    "vocab = n_most_frequent_words_per_author(\n",
    "    fed_papers[fed_papers.author.isin(['Hamilton','Madison'])],\n",
    "    n = 1500, \n",
    "    words_to_ignore=punct) \n",
    "print(f\"Vocab size = {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Train Model</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = fed_papers[fed_papers.author.isin(['Hamilton','Madison'])]\n",
    "\n",
    "#build model\n",
    "model = AuthorshipAttributionMulti(data_train,\n",
    "                                   min_cnt=0,\n",
    "                                   vocab=vocab,\n",
    "                                   gamma=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses performance using leave-one-out HC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.compute_inter_similarity(LOO = True, wrt_authors=['Hamilton', 'Madison'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 8 x 8 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: HC_Hamilton_vs_Madison.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (640 x 480)>\n"
     ]
    }
   ],
   "source": [
    "# illustrate HC scores \n",
    "path_to_plots = \"\"\n",
    "\n",
    "plotnine.options.figure_size = (6.4, 4.8)\n",
    "p = (plot_author_pair(df, value = 'HC') + \n",
    "     theme(legend_title = element_blank(), legend_position = \"top\",\n",
    "            plot_title = element_text(hjust = 0.5, size=16), \n",
    "            legend_text=element_text(size=12),\n",
    "            axis_title_x = element_text(size = 14),\n",
    "            axis_title_y = element_text(size = 14))\n",
    "    ) + xlim(0,8) + ylim(0,8)\n",
    "\n",
    "p.save(path_to_plots + 'HC_Hamilton_vs_Madison.png', height = 8 , width = 8)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate HC-Discrepancies of the Disputed Papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.82it/s]\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 8 x 8 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: HC_Hamilton_vs_Madison_all.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (640 x 480)>\n",
      "<ggplot: (640 x 480)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "# Authiorship of disputed papers:\n",
    "data_disputed = fed_papers[fed_papers.author == 'disputed']\n",
    "\n",
    "# In order to get the results in [1], set LOO=True \n",
    "df_disputed = model.stats_list(data_disputed, LOO = True)  \n",
    "\n",
    "# illustrate HC scores\n",
    "\n",
    "df_all = pd.concat([df, df_disputed], sort = True)\n",
    "\n",
    "p = (plot_author_pair(df_all, value = 'HC', wrt_authors=['Hamilton','Madison']) + theme(legend_title = element_blank(), legend_position = \"none\",\n",
    "            plot_title = element_text(hjust = 0.5, size=16), \n",
    "            legend_text= element_text(size=14),\n",
    "            axis_title_x = element_text(size = 16),\n",
    "            axis_title_y = element_text(size = 16))\n",
    "      + xlim(0,8) + ylim(0,8) )\n",
    "p.save(path_to_plots + 'HC_Hamilton_vs_Madison_all.png', height = 8 , width = 8)\n",
    "print(p \n",
    "     )\n",
    "\n",
    "p = plot_LDA(df_all, value = 'HC',\n",
    "             wrt_authors=['Hamilton','Madison']\n",
    "            ) \n",
    "print(p + ggtitle(\"LDA of scores\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>P-values in rank-based test</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_author_pair_col(df, value, wrt_authors, test_author):\n",
    "    df1 = df.filter(['doc_id', 'author', 'wrt_author', value])\\\n",
    "            .pivot_table(index = ['doc_id','author'],\n",
    "                         columns = 'wrt_author',\n",
    "                         values = [value])[value].reset_index()\n",
    "\n",
    "    \n",
    "    df1.loc[:, 'x'] = df1.loc[:, wrt_authors[0]].astype('float')\n",
    "    df1.loc[:, 'y'] = df1.loc[:, wrt_authors[1]].astype('float')\n",
    "\n",
    "    \n",
    "    df2 = df1.melt(['author', 'doc_id'], ['x', 'y'],\n",
    "                   var_name='wrt_author')\n",
    "    df2.wrt_author = df2.wrt_author.str.replace('x',\n",
    "                                                wrt_authors[0]).replace(\n",
    "                                                    'y', wrt_authors[1])\n",
    "    df2.doc_id = df2.doc_id.astype(int).astype(str)\n",
    "\n",
    "    p = (ggplot(data=df2[df2.author == test_author], mapping = aes(x='doc_id', y='value', fill='wrt_author')) +\n",
    "         geom_bar(position='dodge', stat=\"identity\", show_legend=False, width=.5) +\n",
    "         xlab('Document ID') + ylab(value) +\n",
    "         scale_fill_manual(values=LIST_OF_COLORS) +\n",
    "         theme(legend_title=element_blank(), legend_position='top'))\n",
    "    #ggtitle('Rank wrt each author ' + labels[0] + ' vs '+ labels[1])\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 4 x 8 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: pvals_wrt_author_bar.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (300 x 400)>\n"
     ]
    }
   ],
   "source": [
    "# P-values in rank-based test:\n",
    "\n",
    "plotnine.options.figure_size = (3, 4) #height = 8, width = 5\n",
    "df_all.loc[:,'pval'] = 1-df_all.loc[:,'HC_rank']\n",
    "\n",
    "df_all['rel_rank'] = 1 - df_all['pval']\n",
    "p = plot_author_pair_col(df_all, value = 'rel_rank', \n",
    "                         wrt_authors = ('Hamilton', 'Madison'),\n",
    "                         test_author='disputed') +\\\n",
    "theme(axis_title_x = element_text(size = 14),\n",
    "      axis_title_y = element_text(size = 14),\n",
    "      legend_text = element_text(size=12),\n",
    "     ) + ylab('relative rank') + xlab('disputed article ID')\n",
    "\n",
    "p.save(path_to_plots + 'pvals_wrt_author_bar.png', height = 8 , width = 4)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Discriminiating Words</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 2 x 5 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: discriminating_words_Federalists_1500w_0.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (200 x 500)>\n",
      "<ggplot: (200 x 500)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 2 x 5 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: discriminating_words_Federalists_1500w_1.png\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 2 x 5 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: discriminating_words_Federalists_1500w_2.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (200 x 500)>\n"
     ]
    }
   ],
   "source": [
    "# word discriminating between the two corpora:\n",
    "df1 = model.two_author_test('Hamilton','Madison')\n",
    "df1 =df1.sort_values('pval')\n",
    "\n",
    "df_discriminating = df1[~np.isnan(df1.sign)]\n",
    "plotnine.options.figure_size = (2, 5)\n",
    "\n",
    "for i in [0,1,2] :\n",
    "    k = 25\n",
    "    p = (plot_col(df_discriminating.rename(columns={'feature' : 'term'})[i*k:k*(i+1)],\n",
    "                 value='pval',sign='sign',wrt_authors=('Hamilton','Madison'),\n",
    "                ) + ylab('P-value (binomial)')\n",
    "                + theme(legend_position=\"none\",\n",
    "                )  \n",
    "        )\n",
    "    p.save(path_to_plots + f'discriminating_words_Federalists_1500w_{i}.png', height = 5 , width = 2)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Using ``non-contextual'' words from [1]</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MW_final = [\"upon\", \"also\" ,\"an\", \"by\" , \"of\", \"on\", \"there\", \"this\", \"to\", \"although\", \"both\", \"enough\", \n",
    "    \"while\", \"whilst\", \"always\", \"though\", \"commonly\", \"consequently\", \"considerable\",\n",
    "    \"according\", \"apt\", \"direction\", \"innovation\", \"language\", \"vigor\", \"kind\",\n",
    "    \"matter\", \"particularly\", \"probability\", \"work\"]\n",
    "\n",
    "function_words =  ['a','as','do','has','is','no','or','than','this','when',\n",
    "  'all','at','down','have','it','not','our','that','to','which',\n",
    "  'also','be','even','her','its','now','shall','the','up','who',\n",
    "  'an','been','every','his','may','of','should','their','upon','will',\n",
    "  'and','but','for','if','more','on','so','then','was','with',\n",
    "  'any','by','from','in','must','one','some','there','were','would',\n",
    "  'are','can','had','into','my','only','such','thing','what','your']\n",
    "\n",
    "# two list of additional words used by Mosteller & Wallace\n",
    "additional_words1 = ['affect','city','direction','innovation','perhaps','vigor',\n",
    "                    'again','commonly','disgracing','join','rapid','violate','although',\n",
    "                    'consequently','either','language','sarne','violence','among','considerable',\n",
    "                    'enough','most','second','voice','another','contribute','nor','still',\n",
    "                    'where','because','defensive','fortune','offensive','those','whether',\n",
    "                    'between','destruction','function','often','throughout', 'while','both',\n",
    "                    'did','himself','pass','under','whilst']\n",
    "\n",
    "additional_words2 = ['about','choice','proper','according','common','kind','propriety','adversaries',\n",
    "                    'danger','large','provision','after','decide','decides','decided','deciding',\n",
    "                    'likely','requiisite','aid','degree','matters','matter','substance','always',\n",
    "                    'during','moreover','they','apt','expence','expences','necessary','though',\n",
    "                    'asserted','expenses','expense','necessity','necessities','truth','truths',\n",
    "                    'before','extent','others','us','being','follows','follow','particularly',\n",
    "                    'usages','usage','better','I','principle','we','care','imagine','edit','editing',\n",
    "                    'probability','work']\n",
    "\n",
    "MW_vocab = function_words + additional_words1 + additional_words2\n",
    "\n",
    "\n",
    "#from text_processing import remove_parts_of_speach\n",
    "\n",
    "def lemmatize_vocab(list_of_words) :\n",
    "    return remove_parts_of_speach(\" \".join(list_of_words), to_remove=[]).split()\n",
    "\n",
    "# use 176 words considered in [1] :\n",
    "vocab = lemmatize_vocab(MW_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n"
     ]
    }
   ],
   "source": [
    "train_data = fed_papers[fed_papers.author.isin(['Hamilton','Madison'])]\n",
    "model_NC = AuthorshipAttributionMulti(train_data, \n",
    "                                      vocab = MW_vocab\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/Downloads/HCAuthorship/Federalists/../AuthAttLib/AuthAttLib.py:349: DeprecationWarning: Use 'AuthorshipAttributionMulti.compute_inter_similarity' and 'AuthorshipAttributionMulti.get_inter_similarity' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (200 x 500)>\n",
      "<ggplot: (200 x 500)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "# HC score of each document with respect to the rest in training set\n",
    "df_NC = model_NC.internal_stats()\n",
    "\n",
    "# illustrate HC scores \n",
    "p = plot_author_pair(df_NC, value = 'HC')\n",
    "print(p)\n",
    "\n",
    "p = plot_LDA(df_NC, value = 'HC', wrt_authors=('Hamilton','Madison'))\n",
    "print( p + ggtitle('LDA of HC scores'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (200 x 500)>\n",
      "<ggplot: (200 x 500)>\n",
      "<ggplot: (200 x 500)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "# Authiorship of disputed papers:\n",
    "data_disputed = fed_papers[fed_papers.author == 'disputed']\n",
    "\n",
    "# In order to get the results in [1], set LOO=True \n",
    "df_NC_disputed = model_NC.stats_list(data_disputed, LOO = False)  \n",
    "\n",
    "# illustrate HC scores\n",
    "\n",
    "df_NC_all = pd.concat([df_NC, df_NC_disputed], sort = False)\n",
    "\n",
    "p = plot_author_pair(df_NC_all, value = 'HC', wrt_authors=['Hamilton','Madison'])\n",
    "print(p + ggtitle(\"HC scored wrt to each corpus\"))\n",
    "\n",
    "p = plot_LDA(df_NC_all, value = 'HC',\n",
    "             wrt_authors=['Hamilton','Madison']\n",
    "            )\n",
    "print(p + ggtitle(\"LDA of scores\"))\n",
    "\n",
    "\n",
    "# P-values in rank-based test:\n",
    "df_NC_all.loc[:,'pval'] = 1-df_NC_all.loc[:,'HC_rank']\n",
    "\n",
    "p = plot_author_pair_col(df_NC_all, value = 'pval', wrt_authors = ('Hamilton', 'Madison'), test_author='disputed') +\\\n",
    "theme(legend_title=element_blank(), legend_position='top') + ylab('p-value (rank test)') + xlab('disputed article ID')\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate Three Fequency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine\n",
    "\n",
    "plotnine.options.figure_size = (3, 5)\n",
    "\n",
    "all_data = fed_papers[fed_papers.author.isin(['Hamilton','Madison', 'disputed'])]\n",
    "\n",
    "#prepare model\n",
    "\n",
    "model = AuthorshipAttributionMulti(all_data,\n",
    "                                   min_cnt=0,\n",
    "                                   vocab=vocab,\n",
    "                                   gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 60\n",
    "k1 = 500\n",
    "f1 = model._AuthorModel['Hamilton']._counts\n",
    "f2 = model._AuthorModel['Madison']._counts\n",
    "\n",
    "dtm = model._AuthorModel['disputed']._dtm\n",
    "i = np.random.randint(dtm.shape[0])\n",
    "f3 = np.asarray(dtm[i].todense())[0]\n",
    "dfs = pd.DataFrame({'word' : vocab, 'Hamilton' : f1 / f1.sum(), 'Madison' : f2 / f2.sum(), 'disputed' : f3/f3.sum()})\n",
    "\n",
    "dfs['total'] = dfs['Hamilton'] + dfs['Madison'] + dfs['disputed']\n",
    "dfs = dfs.sort_values('total', ascending=False)\\\n",
    "       .head(k1)\\\n",
    "       .sample(n=k, replace = True)\\\n",
    "       .sort_values('total', ascending=False)\\\n",
    "       .reset_index()\\\n",
    "       .drop(['index','total'], axis=1)\n",
    "       \n",
    "lo_words = dfs.word.tolist()[::-1]\n",
    "dfs['word'] = pd.Categorical(dfs['word'], categories = np.unique(lo_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 3 x 5 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: word_freq_table_exm_0.png\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (300 x 500)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 3 x 5 in image.\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: word_freq_table_exm_1.png\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "/Users/abhishekchakraborty/miniforge3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (300 x 500)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df1['f'] = -np.log10(df1['f'])\n",
    "L = len(dfs) // 2\n",
    "\n",
    "for i in [0, 1] :\n",
    "    df1 = dfs.loc[i*L:(i+1)*L,:].melt(id_vars = 'word', var_name = 'author', value_name= 'f')\n",
    "    p = (ggplot(data=df1, mapping = aes(x = 'word', y = 'f', shape='author')) + \n",
    "             #geom_bar(position='dodge', stat=\"identity\", show_legend=False, size=.5) +\n",
    "             geom_segment(aes(xend='word', y=0, yend='f', fill='word'), show_legend=False, alpha=.1, size=1.5) +\n",
    "             geom_point(aes(color='author'), show_legend=False, size=2) +\n",
    "             scale_color_manual(values = LIST_OF_COLORS) +\n",
    "             coord_flip() + \n",
    "             scale_y_log10() +\n",
    "             ylab('frequency') +\n",
    "             xlab('') +\n",
    "             theme(legend_position='top', legend_title=element_blank(),\n",
    "                     legend_text=element_text(size=12),\n",
    "                     axis_text_y=element_text(size=10)\n",
    "                                )\n",
    "\n",
    "            )\n",
    "    p.save(f\"word_freq_table_exm_{i}.png\")\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
